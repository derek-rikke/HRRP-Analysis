{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3db082ba",
   "metadata": {},
   "source": [
    "\n",
    "# ETL – CMS HRRP Hospital Readmissions (Auto-Load FY CSVs)\n",
    "\n",
    "This notebook auto-loads all CSVs in `../data/raw/`, infers the Fiscal Year (FY) from filenames, and produces Tableau-ready outputs for the two dashboards:\n",
    "1) **National & State Trends**\n",
    "2) **Hospital Distribution & Outliers**\n",
    "\n",
    "Key behavior:\n",
    "- Robust header normalization (case/underscores/squashed).\n",
    "- Suppression-aware (flags & splits \"Too Few to Report\"/missing volume rows).\n",
    "- Clean merges and saved aggregates for Tableau.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcf733c",
   "metadata": {},
   "source": [
    "### Silent mode\n",
    "Configure warnings/display to avoid noisy outputs or revealing local paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "934f7eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\derek\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Silence warnings (including chained assignment and pathy stack traces)\n",
    "import warnings, pandas as _pd, os as _os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "_pd.options.mode.chained_assignment = None\n",
    "# Optional: cap display widths\n",
    "_pd.set_option(\"display.max_colwidth\", 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640185e3",
   "metadata": {},
   "source": [
    "## Step 1 — Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "517b045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "import re, glob\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "RAW = Path(\"../data/raw\")\n",
    "PROC = Path(\"../data/processed\")\n",
    "PROC.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 120)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c043b58a",
   "metadata": {},
   "source": [
    "\n",
    "## Step 2 — Auto-load all FY CSVs and tag metadata\n",
    "\n",
    "- Loads every `*.csv` in `../data/raw/`\n",
    "- Extracts FY from the filename (pattern like `fy_2024_...` or `FY_2025_...`)\n",
    "- Stores temporary columns `__fy` and `__src`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed7f0696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fy_2021_hospital_readmissions_reduction_program_hospital.csv',\n",
       "  2021,\n",
       "  (19224, 14)),\n",
       " ('fy_2022_hospital_readmissions_reduction_program_hospital.csv',\n",
       "  2022,\n",
       "  (19020, 14)),\n",
       " ('fy_2023_hospital_readmissions_reduction_program_hospital.csv',\n",
       "  2023,\n",
       "  (18990, 14)),\n",
       " ('fy_2024_hospital_readmissions_reduction_program_hospital.csv',\n",
       "  2024,\n",
       "  (18774, 14)),\n",
       " ('FY_2025_Hospital_Readmissions_Reduction_Program_Hospital.csv',\n",
       "  2025,\n",
       "  (18510, 14))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def infer_fy_from_name(name: str) -> int | None:\n",
    "    m = re.search(r\"[Ff][Yy]_?(\\d{4})\", name)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "paths = sorted(RAW.glob(\"*.csv\"))\n",
    "assert paths, f\"No CSV files found in {RAW.resolve()}\"\n",
    "\n",
    "raw_frames = []\n",
    "for p in paths:\n",
    "    fy = infer_fy_from_name(p.name)\n",
    "    df = pd.read_csv(p, dtype=str)\n",
    "    df[\"__fy\"] = fy\n",
    "    df[\"__src\"] = p.name\n",
    "    raw_frames.append(df)\n",
    "\n",
    "[(f[\"__src\"].iloc[0], f[\"__fy\"].iloc[0], f.shape) for f in raw_frames]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ba5e71",
   "metadata": {},
   "source": [
    "\n",
    "## Step 3 — Normalize schema (by header name)\n",
    "\n",
    "We canonicalize headers by:\n",
    "- lowercasing\n",
    "- stripping non-alphanumerics to create a key\n",
    "- mapping to a canonical snake_case schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07398752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['facility_id',\n",
       " 'facility_name',\n",
       " 'state',\n",
       " 'measure_name',\n",
       " 'number_of_discharges',\n",
       " 'number_of_readmissions',\n",
       " 'predicted_readmission_rate',\n",
       " 'expected_readmission_rate',\n",
       " 'excess_readmission_ratio',\n",
       " 'start_date',\n",
       " 'end_date',\n",
       " 'footnote',\n",
       " '__fy',\n",
       " '__src']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def canon_key(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]\", \"\", s.lower())\n",
    "\n",
    "MAP = {\n",
    "    \"facilityname\": \"facility_name\",\n",
    "    \"facilityid\": \"facility_id\",\n",
    "    \"state\": \"state\",\n",
    "    \"measurename\": \"measure_name\",\n",
    "    \"numberofdischarges\": \"number_of_discharges\",\n",
    "    \"numberofreadmissions\": \"number_of_readmissions\",\n",
    "    \"predictedreadmissionrate\": \"predicted_readmission_rate\",\n",
    "    \"expectedreadmissionrate\": \"expected_readmission_rate\",\n",
    "    \"excessreadmissionratio\": \"excess_readmission_ratio\",\n",
    "    \"startdate\": \"start_date\",\n",
    "    \"enddate\": \"end_date\",\n",
    "    \"footnote\": \"footnote\",\n",
    "}\n",
    "\n",
    "CANON_COLS = [\n",
    "    \"facility_id\",\"facility_name\",\"state\",\"measure_name\",\n",
    "    \"number_of_discharges\",\"number_of_readmissions\",\n",
    "    \"predicted_readmission_rate\",\"expected_readmission_rate\",\"excess_readmission_ratio\",\n",
    "    \"start_date\",\"end_date\",\"footnote\",\"__fy\",\"__src\"\n",
    "]\n",
    "\n",
    "norm_frames = []\n",
    "for df in raw_frames:\n",
    "    ren = {c: MAP.get(canon_key(c), c) for c in df.columns}\n",
    "    df = df.rename(columns=ren).copy()\n",
    "    # ensure presence\n",
    "    for col in CANON_COLS:\n",
    "        if col not in df.columns:\n",
    "            df[col] = pd.NA\n",
    "    df = df[CANON_COLS]\n",
    "    norm_frames.append(df)\n",
    "\n",
    "norm_frames[0].columns.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad59af7",
   "metadata": {},
   "source": [
    "\n",
    "## Step 4 — Quick validation snapshots (coverage & missingness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d10877b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FY 2021 ===\n",
      "Rows: 19224\n",
      "States: 51 Measures: 6\n",
      "number_of_discharges          0.415\n",
      "number_of_readmissions        0.422\n",
      "predicted_readmission_rate    0.278\n",
      "expected_readmission_rate     0.278\n",
      "excess_readmission_ratio      0.278\n",
      "dtype: float64\n",
      "=== FY 2022 ===\n",
      "Rows: 19020\n",
      "States: 51 Measures: 6\n",
      "number_of_discharges          0.460\n",
      "number_of_readmissions        0.468\n",
      "predicted_readmission_rate    0.297\n",
      "expected_readmission_rate     0.297\n",
      "excess_readmission_ratio      0.297\n",
      "dtype: float64\n",
      "=== FY 2023 ===\n",
      "Rows: 18990\n",
      "States: 51 Measures: 6\n",
      "number_of_discharges          0.508\n",
      "number_of_readmissions        0.519\n",
      "predicted_readmission_rate    0.320\n",
      "expected_readmission_rate     0.320\n",
      "excess_readmission_ratio      0.320\n",
      "dtype: float64\n",
      "=== FY 2024 ===\n",
      "Rows: 18774\n",
      "States: 51 Measures: 6\n",
      "number_of_discharges          0.569\n",
      "number_of_readmissions        0.580\n",
      "predicted_readmission_rate    0.357\n",
      "expected_readmission_rate     0.357\n",
      "excess_readmission_ratio      0.357\n",
      "dtype: float64\n",
      "=== FY 2025 ===\n",
      "Rows: 18510\n",
      "States: 51 Measures: 6\n",
      "number_of_discharges          0.549\n",
      "number_of_readmissions        0.356\n",
      "predicted_readmission_rate    0.356\n",
      "expected_readmission_rate     0.356\n",
      "excess_readmission_ratio      0.356\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for df in norm_frames:\n",
    "    fy = df[\"__fy\"].iloc[0]\n",
    "    print(f\"=== FY {fy} ===\")\n",
    "    print(\"Rows:\", len(df))\n",
    "    print(\"States:\", df[\"state\"].nunique(), \"Measures:\", df[\"measure_name\"].nunique())\n",
    "    print(df[[\"number_of_discharges\",\"number_of_readmissions\",\n",
    "              \"predicted_readmission_rate\",\"expected_readmission_rate\",\"excess_readmission_ratio\"]]\n",
    "          .isna().mean().round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab861b1",
   "metadata": {},
   "source": [
    "\n",
    "## Step 5 — Clean types, flag suppression, split kept vs suppressed\n",
    "\n",
    "Rules:\n",
    "- `suppressed=True` if (`number_of_discharges` **or** `number_of_readmissions` is null) **or** any cell in the row contains `\"Too Few to Report\"`.\n",
    "- Parse dates, coerce numerics.\n",
    "- Split into:\n",
    "  - **kept**: rows suitable for analysis (metrics present)\n",
    "  - **suppressed**: rows excluded from metrics (kept for transparency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5491ce4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  facility_id                     facility_name state            measure_name  number_of_discharges  \\\n",
       " 0       10001  SOUTHEAST ALABAMA MEDICAL CENTER    AL  READM-30-HIP-KNEE-HRRP                 258.0   \n",
       " 1       10001  SOUTHEAST ALABAMA MEDICAL CENTER    AL      READM-30-CABG-HRRP                 268.0   \n",
       " \n",
       "    number_of_readmissions  predicted_readmission_rate  expected_readmission_rate  excess_readmission_ratio start_date  \\\n",
       " 0                    17.0                      5.4150                     4.6146                    1.1735 2016-07-01   \n",
       " 1                    41.0                     13.8076                    11.6339                    1.1868 2016-07-01   \n",
       " \n",
       "     end_date    FY  \n",
       " 0 2019-06-30  2021  \n",
       " 1 2019-06-30  2021  ,\n",
       "   facility_id             facility_name state        measure_name start_date   end_date    FY\n",
       " 7       10005  MARSHALL MEDICAL CENTERS    AL   READM-30-AMI-HRRP 2016-07-01 2019-06-30  2021\n",
       " 9       10005  MARSHALL MEDICAL CENTERS    AL  READM-30-CABG-HRRP 2016-07-01 2019-06-30  2021)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "kept_frames = []\n",
    "supp_frames = []\n",
    "\n",
    "for df in norm_frames:\n",
    "    # detect 'Too Few to Report' in any column\n",
    "    too_few_any = df.astype(str).apply(lambda col: col.str.contains(\"Too Few\", na=False)).any(axis=1)\n",
    "\n",
    "    suppressed = (\n",
    "        df[\"number_of_discharges\"].isna() |\n",
    "        df[\"number_of_readmissions\"].isna() |\n",
    "        too_few_any\n",
    "    )\n",
    "    df[\"suppressed\"] = suppressed\n",
    "\n",
    "    # parse dates\n",
    "    df[\"start_date\"] = pd.to_datetime(df[\"start_date\"], errors=\"coerce\", infer_datetime_format=True)\n",
    "    df[\"end_date\"]   = pd.to_datetime(df[\"end_date\"],   errors=\"coerce\", infer_datetime_format=True)\n",
    "\n",
    "    # numerics\n",
    "    for c in [\"number_of_discharges\",\"number_of_readmissions\",\n",
    "              \"predicted_readmission_rate\",\"expected_readmission_rate\",\"excess_readmission_ratio\"]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    kept = df[~df[\"suppressed\"]].copy()\n",
    "    supp = df[df[\"suppressed\"]].copy()\n",
    "\n",
    "    # add FY\n",
    "    kept[\"FY\"] = df[\"__fy\"].iloc[0]\n",
    "    supp[\"FY\"] = df[\"__fy\"].iloc[0]\n",
    "\n",
    "    # drop helpers\n",
    "    for fr in (kept, supp):\n",
    "        fr.drop(columns=[\"__fy\",\"__src\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "    # suppressed: drop metric cols\n",
    "    METRICS = [\"number_of_discharges\",\"number_of_readmissions\",\n",
    "               \"predicted_readmission_rate\",\"expected_readmission_rate\",\"excess_readmission_ratio\"]\n",
    "    supp = supp.drop(columns=METRICS + [\"suppressed\",\"footnote\"], errors=\"ignore\")\n",
    "\n",
    "    # kept: drop flags & footnote; enforce metrics present\n",
    "    kept = kept.drop(columns=[\"suppressed\",\"footnote\"], errors=\"ignore\")\n",
    "    kept = kept.dropna(subset=[\"excess_readmission_ratio\"])\n",
    "\n",
    "    kept_frames.append(kept)\n",
    "    supp_frames.append(supp)\n",
    "\n",
    "# sanity\n",
    "kept_frames[0].head(2), supp_frames[0].head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bcd64c",
   "metadata": {},
   "source": [
    "\n",
    "## Step 6 — Combine & persist; suppression summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03b3c147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ..\\data\\processed\\readmissions_cleaned.csv ..\\data\\processed\\readmissions_suppressed.csv ..\\data\\processed\\suppression_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((46376, 12),\n",
       " (48142, 7),\n",
       "      FY  total_rows  suppressed_rows  kept_rows  pct_suppressed\n",
       " 0  2021       19224             8121      11103           42.24\n",
       " 1  2022       19020             8900      10120           46.79\n",
       " 2  2023       18990             9848       9142           51.86\n",
       " 3  2024       18774            10884       7890           57.97\n",
       " 4  2025       18510            10389       8121           56.13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kept_all = pd.concat(kept_frames, ignore_index=True)\n",
    "supp_all = pd.concat(supp_frames, ignore_index=True)\n",
    "\n",
    "# Summary by FY\n",
    "summ = []\n",
    "for df in norm_frames:\n",
    "    fy = df[\"__fy\"].iloc[0]\n",
    "    total = len(df)\n",
    "    suppressed_cnt = int(df[\"suppressed\"].sum())\n",
    "    summ.append({\n",
    "        \"FY\": fy,\n",
    "        \"total_rows\": total,\n",
    "        \"suppressed_rows\": suppressed_cnt,\n",
    "        \"kept_rows\": total - suppressed_cnt,\n",
    "        \"pct_suppressed\": round(100 * suppressed_cnt / total, 2)\n",
    "    })\n",
    "suppression_summary = pd.DataFrame(summ).sort_values(\"FY\")\n",
    "\n",
    "# Save (CSV)\n",
    "( PROC / \"readmissions_cleaned.csv\" ).write_text(\"\")  # ensure path exists cross-platform (noop if exists)\n",
    "kept_all.to_csv(PROC / \"readmissions_cleaned.csv\", index=False)\n",
    "supp_all.to_csv(PROC / \"readmissions_suppressed.csv\", index=False)\n",
    "suppression_summary.to_csv(PROC / \"suppression_summary.csv\", index=False)\n",
    "\n",
    "print(\"Saved:\", \n",
    "      PROC / \"readmissions_cleaned.csv\", \n",
    "      PROC / \"readmissions_suppressed.csv\", \n",
    "      PROC / \"suppression_summary.csv\")\n",
    "kept_all.shape, supp_all.shape, suppression_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247caba0",
   "metadata": {},
   "source": [
    "\n",
    "## Step 7 — Tableau-ready aggregates\n",
    "- **state_summary.csv**: FY × state × measure with avg ERR, counts, and delta vs prior.\n",
    "- **national_summary.csv**: FY × measure with national avg ERR.\n",
    "- **hospital_summary.csv**: row-level for distributions/outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b61e928e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ..\\data\\processed\\state_summary.csv ..\\data\\processed\\national_summary.csv ..\\data\\processed\\hospital_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1496, 7), (30, 3), (46376, 9))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# State summary\n",
    "state_summary = (\n",
    "    kept_all.groupby([\"FY\",\"state\",\"measure_name\"], dropna=False)\n",
    "            .agg(\n",
    "                avg_err=(\"excess_readmission_ratio\",\"mean\"),\n",
    "                hospitals_reporting=(\"facility_id\",\"nunique\"),\n",
    "                total_rows=(\"facility_id\",\"size\")\n",
    "            )\n",
    "            .reset_index()\n",
    "            .sort_values([\"FY\",\"measure_name\",\"state\"])\n",
    ")\n",
    "state_summary[\"delta_prev\"] = (\n",
    "    state_summary.groupby([\"state\",\"measure_name\"])[\"avg_err\"].diff()\n",
    ")\n",
    "\n",
    "# National summary (mean of state averages)\n",
    "national_summary = (\n",
    "    state_summary.groupby([\"FY\",\"measure_name\"], dropna=False)\n",
    "                 .agg(national_avg_err=(\"avg_err\",\"mean\"))\n",
    "                 .reset_index()\n",
    "                 .sort_values([\"FY\",\"measure_name\"])\n",
    ")\n",
    "\n",
    "# Hospital summary\n",
    "hospital_summary = kept_all.loc[:, [\n",
    "    \"FY\",\"facility_id\",\"facility_name\",\"state\",\"measure_name\",\n",
    "    \"excess_readmission_ratio\",\"number_of_discharges\",\"number_of_readmissions\"\n",
    "]].copy()\n",
    "hospital_summary = hospital_summary.rename(columns={\"excess_readmission_ratio\": \"err\"})\n",
    "hospital_summary[\"rank_by_err\"] = (\n",
    "    hospital_summary.groupby([\"FY\",\"measure_name\"])[\"err\"]\n",
    "                    .rank(method=\"dense\", ascending=True)\n",
    ")\n",
    "\n",
    "# Save (CSV)\n",
    "state_summary.to_csv(PROC / \"state_summary.csv\", index=False)\n",
    "national_summary.to_csv(PROC / \"national_summary.csv\", index=False)\n",
    "hospital_summary.to_csv(PROC / \"hospital_summary.csv\", index=False)\n",
    "\n",
    "print(\"Saved:\", \n",
    "      PROC / \"state_summary.csv\", \n",
    "      PROC / \"national_summary.csv\", \n",
    "      PROC / \"hospital_summary.csv\")\n",
    "state_summary.shape, national_summary.shape, hospital_summary.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
